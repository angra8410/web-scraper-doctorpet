# Web Scraper para DoctorPet.co - CategorÃ­a Alimentos

> ğŸ¯ **Orientado a desarrolladores junior** - Este proyecto incluye documentaciÃ³n detallada y explicaciones paso a paso para facilitar el aprendizaje.

## ğŸ“‹ DescripciÃ³n

Este es un web scraper en Python diseÃ±ado para extraer informaciÃ³n de productos de la categorÃ­a "Alimentos" del sitio web [DoctorPet.co](https://doctorpet.co/producto-category/alimentos/).

### Â¿QuÃ© es un web scraper?

Un web scraper es un programa que automÃ¡ticamente visita pÃ¡ginas web y extrae informaciÃ³n especÃ­fica de ellas. Piensa en Ã©l como un "robot lector" que puede:
- Abrir pÃ¡ginas web
- Leer su contenido HTML
- Buscar informaciÃ³n especÃ­fica (como nombres de productos, precios, etc.)
- Guardar esa informaciÃ³n en un formato estructurado (como CSV)

## âœ¨ CaracterÃ­sticas

El scraper extrae la siguiente informaciÃ³n de cada producto:
- âœ… **Nombre del producto**
- âœ… **Precio** (incluyendo precios en oferta)
- âœ… **Disponibilidad** (Disponible/Agotado)
- âœ… **Enlace** al producto
- âœ… **Imagen** del producto

AdemÃ¡s, incluye:
- ğŸ”„ **Manejo automÃ¡tico de paginaciÃ³n** - Recorre todas las pÃ¡ginas de la categorÃ­a
- â±ï¸ **Delays entre peticiones** - Evita sobrecargar el servidor y ser bloqueado
- ğŸ” **Reintentos automÃ¡ticos** - Si una peticiÃ³n falla, lo intenta de nuevo
- ğŸ“Š **ExportaciÃ³n a CSV** - Resultados en formato fÃ¡cil de abrir en Excel
- ğŸ“ **Logging detallado** - Muestra el progreso y ayuda a detectar problemas

## ğŸ“ Patrones de DiseÃ±o Aplicados

Este proyecto implementa dos patrones importantes para facilitar el onboarding y comprensiÃ³n:

### 1. Chain of Thought Pattern (Cadena de Pensamiento)

Cada secciÃ³n del cÃ³digo incluye comentarios detallados explicando **por quÃ©** se tomÃ³ cada decisiÃ³n tÃ©cnica, no solo **quÃ©** hace el cÃ³digo.

**Ejemplo:**
```python
# Chain of Thought: Usamos Session en lugar de requests.get() directo porque:
# - Reutiliza conexiones (mÃ¡s eficiente)
# - Mantiene cookies automÃ¡ticamente
# - Permite configurar comportamiento comÃºn para todas las peticiones
self.session = requests.Session()
```

Este patrÃ³n ayuda a:
- Entender el razonamiento detrÃ¡s de las decisiones
- Aprender mejores prÃ¡cticas
- Facilitar futuras modificaciones

### 2. Persona Pattern (Orientado a Desarrollador Junior)

Toda la documentaciÃ³n y comentarios estÃ¡n escritos asumiendo que el lector es un **desarrollador junior** que puede estar aprendiendo:
- Python
- Web scraping
- Peticiones HTTP
- Manejo de archivos CSV

**Ejemplo:**
```python
# Nota para junior: CSV = Comma Separated Values (Valores Separados por Comas)
# Es un formato universal, fÃ¡cil de abrir en Excel/Google Sheets
```

## ğŸš€ InstalaciÃ³n

### Prerrequisitos

- Python 3.7 o superior instalado en tu sistema
- pip (gestor de paquetes de Python)

### Paso 1: Clonar el repositorio

```bash
git clone https://github.com/angra8410/web-scraper-doctorpet.git
cd web-scraper-doctorpet
```

### Paso 2: Instalar dependencias

```bash
pip install -r requirements.txt
```

**Â¿QuÃ© se instalarÃ¡?**
- `requests` - Para hacer peticiones HTTP (visitar pÃ¡ginas web)
- `beautifulsoup4` - Para analizar y extraer datos del HTML
- `lxml` - Parser rÃ¡pido para BeautifulSoup

## ğŸ“– Uso

### Uso bÃ¡sico

Simplemente ejecuta el script:

```bash
python scraper.py
```

El scraper:
1. VisitarÃ¡ la pÃ¡gina de alimentos de DoctorPet.co
2. ExtraerÃ¡ informaciÃ³n de todos los productos
3. NavegarÃ¡ por todas las pÃ¡ginas disponibles
4. GuardarÃ¡ los resultados en un archivo CSV con nombre automÃ¡tico como: `doctorpet_alimentos_20240930_143025.csv`

### Uso avanzado

Si quieres usar el scraper desde otro script Python:

```python
from scraper import DoctorPetScraper

# Crear instancia del scraper
scraper = DoctorPetScraper()

# Scrapear solo las primeras 2 pÃ¡ginas (Ãºtil para testing)
productos = scraper.scrape_category(max_pages=2)

# Guardar en un archivo especÃ­fico
scraper.save_to_csv(productos, filename="mis_productos.csv")
```

## ğŸ“‚ Estructura de Archivos

```
web-scraper-doctorpet/
â”‚
â”œâ”€â”€ scraper.py           # Script principal del scraper
â”œâ”€â”€ test_scraper.py      # Script de pruebas con HTML de ejemplo
â”œâ”€â”€ requirements.txt     # Dependencias del proyecto
â”œâ”€â”€ README.md           # Este archivo
â”œâ”€â”€ .gitignore          # Archivos a ignorar en git
â”‚
â””â”€â”€ doctorpet_alimentos_*.csv  # Archivos CSV generados (ignorados por git)
```

## ğŸ§ª Testing

El proyecto incluye un script de pruebas (`test_scraper.py`) que valida la funcionalidad del scraper usando HTML de ejemplo.

Para ejecutar las pruebas:

```bash
python test_scraper.py
```

Esto validarÃ¡:
- âœ… ExtracciÃ³n correcta de informaciÃ³n de productos
- âœ… Manejo de diferentes formatos de precio (regular y en oferta)
- âœ… DetecciÃ³n de disponibilidad (disponible/agotado)
- âœ… GeneraciÃ³n correcta del archivo CSV

**Â¿Por quÃ© es importante testing?**

El testing con HTML de ejemplo nos permite:
1. Verificar que la lÃ³gica de extracciÃ³n funciona correctamente
2. No depender de la disponibilidad del sitio web real
3. Detectar problemas antes de ejecutar el scraper completo
4. Documentar el comportamiento esperado del cÃ³digo

## ğŸ“Š Formato del CSV

El archivo CSV generado tiene las siguientes columnas:

| nombre | precio | disponibilidad | enlace | imagen |
|--------|--------|----------------|--------|--------|
| Alimento Perro Adulto 15kg | $45.000 | Disponible | https://... | https://... |
| Alimento Gato Cachorro 3kg | $28.000 | Agotado | https://... | https://... |

Puedes abrir este archivo con:
- Microsoft Excel
- Google Sheets
- LibreOffice Calc
- Cualquier editor de texto

## ğŸ”§ ModificaciÃ³n del Scraper

### Cambiar la categorÃ­a a scrapear

Modifica la constante `BASE_URL` en `scraper.py`:

```python
# En lugar de alimentos, scrapear otra categorÃ­a
BASE_URL = "https://doctorpet.co/producto-category/juguetes/"
```

### Ajustar los delays (pausas)

Si el sitio te estÃ¡ bloqueando, aumenta los delays:

```python
DELAY_BETWEEN_REQUESTS = 5  # En lugar de 2 segundos
DELAY_BETWEEN_PRODUCTS = 1  # En lugar de 0.5 segundos
```

**Â¿Por quÃ© son importantes los delays?**
- Evitan sobrecargar el servidor del sitio web
- Previenen que tu IP sea bloqueada
- Son una prÃ¡ctica Ã©tica de web scraping

### Extraer informaciÃ³n adicional

Si quieres extraer mÃ¡s datos (por ejemplo, categorÃ­as, SKU, etc.), modifica el mÃ©todo `_extract_product_info()`:

```python
def _extract_product_info(self, product_element):
    product_data = {
        'nombre': 'N/A',
        'precio': 'N/A',
        # ... campos existentes ...
        'categoria': 'N/A',  # Nuevo campo
    }
    
    # Extraer categorÃ­a
    category_element = product_element.find('span', class_='product-category')
    if category_element:
        product_data['categoria'] = category_element.get_text(strip=True)
    
    # ... resto del cÃ³digo ...
```

No olvides actualizar tambiÃ©n el mÃ©todo `save_to_csv()`:

```python
fieldnames = ['nombre', 'precio', 'disponibilidad', 'enlace', 'imagen', 'categoria']
```

## ğŸ› Troubleshooting (SoluciÃ³n de Problemas)

### Problema 1: "No se encontraron productos"

**Posibles causas:**
1. El sitio web cambiÃ³ su estructura HTML
2. El sitio estÃ¡ bloqueando el scraper
3. Problemas de conectividad

**Soluciones:**
1. Inspecciona manualmente la pÃ¡gina web:
   - Abre https://doctorpet.co/producto-category/alimentos/ en tu navegador
   - Click derecho > "Inspeccionar elemento"
   - Verifica que los productos tengan `class="product"`
   
2. Aumenta los delays entre peticiones
3. Verifica tu conexiÃ³n a internet

### Problema 2: "Error de conexiÃ³n" o "Timeout"

**Posibles causas:**
- Problemas de red
- El sitio web estÃ¡ caÃ­do
- Tu IP puede estar bloqueada

**Soluciones:**
1. Verifica que puedes acceder al sitio desde tu navegador
2. Espera unos minutos y vuelve a intentar
3. Aumenta el `REQUEST_TIMEOUT`:
   ```python
   REQUEST_TIMEOUT = 60  # En lugar de 30 segundos
   ```

### Problema 3: "La estructura HTML ha cambiado"

Los sitios web cambian frecuentemente. Si el scraper deja de funcionar:

1. Inspecciona la pÃ¡gina web actual
2. Identifica las nuevas clases CSS o estructura
3. Actualiza los selectores en `_extract_product_info()`

**Ejemplo:**
Si antes era:
```python
title_element = product_element.find('h2', class_='woocommerce-loop-product__title')
```

Y ahora es:
```python
title_element = product_element.find('h2', class_='product-name')
```

### Problema 4: El archivo CSV tiene caracteres raros

AsegÃºrate de abrir el CSV con codificaciÃ³n UTF-8. En Excel:
1. Datos > Desde texto/CSV
2. Selecciona el archivo
3. Origen del archivo: 65001: Unicode (UTF-8)

## âš ï¸ Consideraciones Ã‰ticas y Legales

### Buenas prÃ¡cticas de web scraping:

1. **Respeta el robots.txt**: Verifica https://doctorpet.co/robots.txt
2. **No sobrecargues el servidor**: Usa delays apropiados
3. **Respeta los tÃ©rminos de servicio**: Lee los tÃ©rminos del sitio web
4. **No hagas scraping de datos personales**: Solo informaciÃ³n pÃºblica de productos
5. **IdentifÃ­cate apropiadamente**: El User-Agent incluye informaciÃ³n real del navegador

### Limitaciones tÃ©cnicas encontradas:

Durante el desarrollo se identificaron los siguientes puntos:

- **DNS/Conectividad**: En algunos entornos (como ambientes de CI/CD, contenedores, o redes corporativas), el dominio `doctorpet.co` puede no resolver correctamente debido a:
  - Configuraciones de red restrictivas
  - Restricciones DNS
  - Firewalls que bloquean ciertos dominios
  - El sitio puede estar temporalmente inaccesible
  
- **SoluciÃ³n implementada**: El cÃ³digo incluye:
  - Reintentos automÃ¡ticos (hasta 3 intentos por peticiÃ³n)
  - Manejo robusto de errores de conexiÃ³n
  - Logging detallado para facilitar diagnÃ³stico
  - Mensajes informativos sobre posibles causas de fallo

- **CÃ³mo probar**: Si encuentras problemas de conectividad:
  1. Verifica que puedes acceder a https://doctorpet.co desde tu navegador
  2. Ejecuta `test_scraper.py` para validar que la lÃ³gica de extracciÃ³n funciona
  3. Si el sitio es accesible desde navegador pero no desde el script, puede ser necesario ajustar headers o usar proxies

### Ejemplo de salida exitosa:

Cuando el scraper funciona correctamente, verÃ¡s una salida similar a:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   DOCTORPET.CO WEB SCRAPER                              â•‘
â•‘                    CategorÃ­a: Alimentos                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

2025-09-30 18:03:56 - INFO - Scraper inicializado para: https://doctorpet.co/producto-category/alimentos/
2025-09-30 18:03:56 - INFO - INICIANDO SCRAPING DE CATEGORÃA
2025-09-30 18:03:56 - INFO - --- PÃ¡gina 1 ---
2025-09-30 18:03:58 - INFO - âœ“ PeticiÃ³n exitosa: 200
2025-09-30 18:03:58 - INFO - Encontrados 24 productos en esta pÃ¡gina
2025-09-30 18:04:02 - INFO - âœ“ ExtraÃ­dos 24 productos de esta pÃ¡gina
2025-09-30 18:04:02 - INFO - Total acumulado: 24 productos
2025-09-30 18:04:02 - INFO - â†’ Siguiente pÃ¡gina encontrada
...
2025-09-30 18:05:15 - INFO - SCRAPING FINALIZADO: 72 productos totales
2025-09-30 18:05:15 - INFO - âœ“ Archivo guardado exitosamente: doctorpet_alimentos_20250930_180515.csv
2025-09-30 18:05:15 - INFO - ğŸ‰ Â¡Scraping completado exitosamente!
```

## ğŸ“š Recursos para Aprender MÃ¡s

Si eres nuevo en web scraping, estos recursos te ayudarÃ¡n:

1. **Python Requests**: https://docs.python-requests.org/
2. **BeautifulSoup**: https://www.crummy.com/software/BeautifulSoup/bs4/doc/
3. **CSS Selectors**: https://www.w3schools.com/cssref/css_selectors.asp
4. **Ã‰tica en Web Scraping**: https://www.scraperapi.com/blog/web-scraping-laws-ethics/

## ğŸ¤ Contribuciones

Si encuentras un bug o tienes una mejora:

1. Abre un Issue describiendo el problema
2. Si tienes una soluciÃ³n, crea un Pull Request
3. AsegÃºrate de documentar tu cambio siguiendo el patrÃ³n Chain of Thought

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para fines educativos.

## ğŸ‘¥ Autor

Desarrollado como ejemplo educativo para onboarding de desarrolladores junior en web scraping.

---

**Â¿Preguntas o problemas?** Abre un issue en el repositorio y te ayudaremos.

